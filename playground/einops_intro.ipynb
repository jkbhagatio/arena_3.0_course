{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://einops.rocks\n",
    "- [einsum is all you need: aladdin persson video](https://www.youtube.com/watch?v=pkVwUVEHmfI)\n",
    "- [einsum is all you need: tim rocktaschel blog](https://rockt.ai/2018/04/30/einsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einsum notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einsum notation for each element in the output matrix, $C$ of shape [i, k], found from matrix multiplication of two matrices, $A$ of shape [i, j] and $B$ of shape [j, k], is defined as:\n",
    "\n",
    "$$\n",
    "C_{ik} = \\sum_{j} A_{i,j} B_{j,k}\n",
    "$$\n",
    "\n",
    "In code (einops), the entire matrix multiplication yielding the full matrix $C$ can be written as:\n",
    "\n",
    "```python\n",
    "c = einops.einsum(a, b, \"i j, j k -> i k\")\n",
    "```\n",
    "\n",
    "where the matrices to be operated on are the first arguments (`a, b`), \n",
    "\n",
    "and the einsum string (`\"i j, j k -> i k\"`) is the last argument. \n",
    "\n",
    "The einsum string contains space-separated values (`\"i j\"` for `a`),\n",
    "\n",
    "where each value corresponds to a dimension (`\"i\"` for `a`'s rows and `\"j\"` for `a`'s columns) in the input matrices. \n",
    "\n",
    "The matrix arguments are comma-separated, and an arrow, `->` yields the space-separated dimensions of the output matrix (`\"i k\"`). \n",
    "\n",
    "Key points to remember about the einsum string:\n",
    "\n",
    "- Shared dimensions in the input matrices (in the example above, `\"j\"`) means we match up and multiply the corresponding elements along these dimensions in the input matrices (obviously, each pair of these dimensions must be the same size).\n",
    "\n",
    "- Any dimensions not specified in the output matrix (in the example above, `\"j\"`) are summed over.\n",
    "\n",
    "- The output axes can be returned in any order (e.g. in the example above, we could have done `\"k i\"` instead of `\"i k\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports.\"\"\"\n",
    "\n",
    "import torch\n",
    "from einops import asnumpy, einsum, rearrange, reduce, repeat, pack, parse_shape, unpack\n",
    "from einops.layers.torch import Rearrange, Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[22, 28],\n",
      "        [49, 64]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Recreate above example in code.\"\"\"\n",
    "\n",
    "# Following the example above, let i=2, j=3, k=2\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "b = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "c = einsum(a, b, \"i j, j k -> i k\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix operations using `einsum`, `rearrange`, `reduce`, and `repeat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutations and rearrangements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create a dataset representing images.\"\"\"\n",
    "\n",
    "x = torch.randn(32, 3, 224, 224)  # assume this is a batch of 32 RGB images of size 224x224\n",
    "x -= x.min()  # ensure all pixels are positive\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 224, 224, 3])\n",
      "torch.Size([32, 224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Simple permutations.\"\"\"\n",
    "\n",
    "# Move the channel axis to the end\n",
    "print(rearrange(x, \"b c x y -> b x y c\").shape)\n",
    "\n",
    "# We can also do this  with einsum\n",
    "print(einsum(x, \"b c x y -> b x y c\").shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 150528])\n",
      "torch.Size([128, 3, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Do more complex rearrangements (e.g. flattens or splits).\"\"\"\n",
    "\n",
    "# Flatten the image dimensions\n",
    "print(rearrange(x, \"b c x y -> b (c x y)\").shape)  \n",
    "\n",
    "# Split each image into 4 quadrants and reconstruct the batch (should be 4x larger)\n",
    "print(rearrange(x, \"b c (x2 x) (y2 y) -> (b x2 y2) c x y\", x2=2, y2=2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einsum takes care of dimension matching, so long as we specify the dimensions correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "\n",
      "tensor([[13, 16],\n",
      "        [40, 52]]) \n",
      "\n",
      "tensor([[ 6, 12, 18],\n",
      "        [ 9, 19, 29],\n",
      "        [12, 26, 40]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Standard matrix multiplications.\"\"\"\n",
    "\n",
    "a = torch.tensor([[0, 1, 2], [3, 4, 5]])\n",
    "b = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "print(a)\n",
    "print(b)\n",
    "print()\n",
    "\n",
    "# Rows of `a` by columns of `b` (same as initial example)\n",
    "# (since 'j' is shared, and represents dim2 of `a` and dim1 of `b`, we take the values along\n",
    "# dim2 of `a` (i.e. its rows) and the values along dim1 of `b` (i.e. its cols) and multiply them\n",
    "# together, and since 'j' is omitted from the output, we sum over it)\n",
    "print(einsum(a, b, \"i j, j k -> i k\"), \"\\n\")\n",
    "\n",
    "# Similarly, we can multiply the columns of `a` by the rows of `b` (without explictly transposing)\n",
    "print(einsum(a, b, \"i j, k i -> j k\"), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  3, 10],\n",
      "        [ 6, 16, 30]]) \n",
      "\n",
      "tensor([[ 0,  6],\n",
      "        [ 3, 16],\n",
      "        [10, 30]]) \n",
      "\n",
      "tensor([ 0,  2,  6, 12, 20, 30]) \n",
      "\n",
      "tensor(315) \n",
      "\n",
      "torch.Size([2, 3, 3, 2]) \n",
      "\n",
      "tensor([ 45, 105, 165]) \n",
      "\n",
      "tensor([[15, 30],\n",
      "        [45, 60],\n",
      "        [75, 90]]) \n",
      "\n",
      "tensor([[  0,  21,  42],\n",
      "        [ 63,  84, 105]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Element-wise multiplications.\"\"\"\n",
    "\n",
    "# We can do row-major hadamard and return the output in either the shape of `a` or `b`\n",
    "print(einsum(a, b, \"i j, j i -> i j\"), \"\\n\")  # shape of `a`\n",
    "print(einsum(a, b, \"i j, j i -> j i\"), \"\\n\")  # shape of `b`\n",
    "\n",
    "# We can do a flat hadamard\n",
    "print(einsum(a.flatten(), b.flatten(), \"n, n -> n\"), \"\\n\")\n",
    "\n",
    "# We can decide to multiply each element in `a` by each element in `b` (by writing all input\n",
    "# dimensions independently), and choose which dimensions to sum over.\n",
    "\n",
    "# Sum over all dimensions\n",
    "print(einsum(a, b, \"i j, k l -> \"), \"\\n\")  \n",
    "\n",
    "# Sum over no dimensions (each element-wise multiplication is a separate element in the output)\n",
    "print(einsum(a, b, \"i j, k l -> i j k l\").shape, \"\\n\")\n",
    "# print(einsum(a, b, \"i j, k l -> i j k l\"), \"\\n\")\n",
    "\n",
    "# Sum over all but the first dimension of the second matrix\n",
    "print(einsum(a, b, \"i j, k l -> k\"), \"\\n\")\n",
    "\n",
    "# Sum over the two dimensions of the first matrix\n",
    "print(einsum(a, b, \"i j, k l -> k l\"), \"\\n\")\n",
    "\n",
    "# Sum over the two dimensions of the second matrix\n",
    "print(einsum(a, b, \"i j, k l -> i j\"), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_weights: {'n_model_instances': 2, 'n_feat': 4, 'n_hidden': 3}\n",
      "feat_vals: {'batch_sz': 2, 'n_model_instances': 2, 'n_feat': 4}\n",
      "acts: {'batch_sz': 2, 'n_model_instances': 2, 'n_hidden': 3} \n",
      "\n",
      "tensor([[[14, 20, 26],\n",
      "         [10, 20, 30]],\n",
      "\n",
      "        [[20, 30, 40],\n",
      "         [ 4, 10, 16]]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Multiplications of matrices with 3+ dimensions and 2+ shared dimensions.\"\"\"\n",
    "\n",
    "# Imagine we have a toy nn model object that holds 2 model instances and that we believe can\n",
    "# represent 4 features in just 3 neurons; we feed into it a batch of feature values.\n",
    "\n",
    "batch_sz, n_model_instances, n_feat, n_hidden = 2, 2, 4, 3\n",
    "\n",
    "model_weights = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [0, 1, 2],\n",
    "            [1, 2, 3],\n",
    "            [2, 3, 4],\n",
    "            [3, 4, 5]\n",
    "        ],\n",
    "        [\n",
    "            [3, 4, 5],\n",
    "            [2, 3, 4],\n",
    "            [1, 2, 3],\n",
    "            [0, 1, 2]\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "feat_vals = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [0, 1, 2, 3],\n",
    "            [1, 2, 3, 4]\n",
    "        ],\n",
    "        [\n",
    "            [1, 2, 3, 4],\n",
    "            [0, 1, 2, 3]\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"model_weights: {parse_shape(model_weights, 'n_model_instances n_feat n_hidden')}\")\n",
    "print(f\"feat_vals: {parse_shape(feat_vals, 'batch_sz n_model_instances n_feat')}\")\n",
    "\n",
    "# We want to get the activations for each of the 3 neurons, for each of the 2 model instances,\n",
    "# for each of the 2 examples in the batch: we multiply the feature values by the model weights,\n",
    "# matching on 'n_model_instances' and 'n_feat', and summing over 'n_feat' (each neuron combines \n",
    "# info from all features).\n",
    "acts = einsum(\n",
    "    feat_vals, \n",
    "    model_weights, \n",
    "    \"batch model_i feat, model_i feat hidden -> batch model_i hidden\"\n",
    ")\n",
    "print(f\"acts: {parse_shape(acts, 'batch_sz n_model_instances n_hidden')} \\n\")\n",
    "print(acts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations (reductions) over dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create a dataset representing images.\"\"\"\n",
    "\n",
    "x = torch.randn(32, 3, 224, 224)  # assume this is a batch of 32 RGB images of size 224x224\n",
    "x -= x.min()  # ensure all pixels are positive\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25579796.)\n",
      "tensor([8527487., 8525645., 8526663.]) \n",
      "\n",
      "tensor(25579796.)\n",
      "tensor([8527487., 8525645., 8526663.]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sum over dimensions.\"\"\"\n",
    "\n",
    "# Sum over all dimensions\n",
    "print(reduce(x, \"b c x y ->\", \"sum\"))\n",
    "# Sum for each channel\n",
    "print(reduce(x, \"b c x y -> c\", \"sum\"), \"\\n\")\n",
    "\n",
    "# We can also do these with einsum\n",
    "print(einsum(x, \"b c x y ->\"))\n",
    "print(einsum(x, \"b c x y -> c\"), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.3110, 5.3098, 5.3105])\n",
      "tensor([0.9999, 1.0011, 0.9993])\n",
      "torch.Size([224, 224])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Perform more complex operations (e.g. mean, min, max, prod) over dimensions.\"\"\"\n",
    "\n",
    "# Mean for each channel\n",
    "print(reduce(x, \"b c x y -> c\", \"mean\"))\n",
    "\n",
    "# Var for each channel\n",
    "print(reduce(x, \"b c x y -> c\", torch.var))\n",
    "\n",
    "# Max for each 224x224 pixel\n",
    "print(reduce(x, \"b c x y -> x y\", \"max\").shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other common matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 5, 9])\n",
      "tensor(15)\n",
      "tensor([ 6, 15, 24])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Working with matrix diagonals.\"\"\"\n",
    "\n",
    "m = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Get the diagonal.\n",
    "print(einsum(m, \"i i -> i\"))\n",
    "\n",
    "# Get the trace.\n",
    "print(einsum(m, \"i i -> \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat a tensor along a new axis or existing axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Along a new axis: add different noise to copies of an image\"\"\"\n",
    "\n",
    "x = torch.randn(3, 224, 224)  # assume this is an RGB image of size 224x224\n",
    "x -= x.min()  # ensure all pixels are positive\n",
    "\n",
    "# Add different noise to each copy of the image\n",
    "x_b = repeat(x, \"c x y -> b c x y\", b=32)\n",
    "noise = torch.randn_like(x_b) * 0.1\n",
    "x_b = x_b + noise\n",
    "print(x_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 448, 224])\n",
      "torch.Size([3, 224, 448])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Along an existing axis: elongate width or height\"\"\"\n",
    "\n",
    "x_wide = repeat(x, \"c x y -> c (w x) y\", w=2)\n",
    "print(x_wide.shape)\n",
    "\n",
    "x_tall = repeat(x, \"c x y -> c x (2 y)\")  # we can also feed a numeric directly into einsum string\n",
    "print(x_tall.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena_3.0_gpu_jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
